# Summarize PPS simulated and empirical data - molecular sequences
# Orlando Schwery, 30. May 2022

# num_post_sims = listFiles(path="output_"+model_name+"/" + analysis_name + "_post_sims").size()
# source("scripts/pps_DataSummary.Rev")


# Settings (some of these might become/be redundant)
rep = 3  # which set to use
current_model = 1  # sets model to use, see below
models = ["TEFBD", "unpart"]
proposed_model = models[current_model]

output_dir = "results/"
file_stem = "time_homo_" + rep

input_dir_emp = "Data/"
input_dir_sim = "PPS_output/"

# Names of sequence files used - should probably be in same order as in original model
markers <- v("18s", "28s", "ABD","Arg", "CAD", "EF1", "EF2", "lg", "WG")
num_markers = markers.size()

morpho_model <- "SHDM"  #"Mk"
n_morpho_states <- 7

# count number of posterior samples
num_post_sims = listFiles(path=input_dir_sim).size()

emp_subset = TRUE  # if emp data needs to be reduced to what sim data was

#############################
# Summary of empirical data #
#############################
colnames <- v("SimID")

outfileName = output_dir + "/empirical_data_" + file_stem + ".csv"

# Molecular Data
for (j in 1:num_markers) {
  # initiate outfile and populate with column names

  colnames2 <- v(
  "Number Invariant Sites" + " " + markers[j],
  "Number Invariant Sites Excluding Ambiguous" + " " + markers[j],
  "Segregating-Sites" + " " + markers[j],
  "Max GC" + " " + markers[j],
  "Max GC Excluding Ambiguous" + " " + markers[j],
  "Max Invariant Block Length" + " " + markers[j],
  "Max Invariant Block Length Excluding Ambiguous" + " " + markers[j],
  "Max Pairwise Difference" + " " + markers[j],
  "Max Pairwise Difference Excluding Ambiguous" + " " + markers[j],
  "Max Variable Block Length" + " " + markers[j],
  "Max Variable Block Length Excluding Ambiguous" + " " + markers[j],
  "Min GC" + " " + markers[j],
  "Min GC Excluding Ambiguous" + " " + markers[j],
  "Min Pairwise Difference" + " " + markers[j],
  "Min Pairwise Difference Excluding Ambiguous" + " " + markers[j],
  "Number Invariable Block" + " " + markers[j],
  "Number Invariable Block Excluding Ambiguous" + " " + markers[j],
  "Mean GC" + " " + markers[j],
  "Mean GC Excluding Ambiguous" + " " + markers[j],
  "Mean GC 1" + " " + markers[j],
  "Mean GC 1 Excluding Ambiguous" + " " + markers[j],
  "Mean GC 2" + " " + markers[j],
  "Mean GC 2 Excluding Ambiguous" + " " + markers[j],
  "Mean GC 3" + " " + markers[j],
  "Mean GC 3 Excluding Ambiguous" + " " + markers[j],
  "Var GC" + " " + markers[j],
  "Var GC Excluding Ambiguous" + " " + markers[j],
  "Var GC 1" + " " + markers[j],
  "Var GC 1 Excluding Ambiguous" + " " + markers[j],
  "Var GC 2" + " " + markers[j],
  "Var GC 2 Excluding Ambiguous" + " " + markers[j],
  "Var GC 3" + " " + markers[j],
  "Var GC 3 Excluding Ambiguous" + " " + markers[j],
  "Theta" + " " + markers[j],
  "Tajima-D" + " " + markers[j],
  "Tajima-Pi" + " " + markers[j],
  "Multinomial-Likelihood" + " " + markers[j]
  )
  colnames2.size()
  colnames.append(colnames2)
  colnames.size()
}

# Morpho Data
# for (k in 1:(n_morpho_states-1)) {  #just pool them all for now, though this may eventually not be reasonable
    colnames3 <- v(
    "Tip State Frequency 0",
    "Tip State Frequency 1",
    "Tip State Frequency 2",
    "Tip State Frequency 3",
    "Tip State Frequency 4",
    "Tip State Frequency 5",
    "Tip State Frequency 6",
    "Number Invariant Sites Morpho",
    "Number Invariant Sites Morpho Excluding Ambiguous",
    "Max Pairwise Difference Morpho",
    "Max Pairwise Difference Morpho Excluding Ambiguous",
    "Min Pairwise Difference Morpho",
    "Min Pairwise Difference Morpho Excluding Ambiguous"
    )
    colnames3.size()
    colnames.append(colnames3)
    colnames.size()
    # later add distinction of using fossil vs extant only, as well as delta of fossil and extant
    # also add state relative time once tracked during inference?
#}


# Fossil ages
# can't do that just yet?
# load and subset trace, within which we got t[i], fossil_normalized[i], and fossil[i]
# compare to fossil min and max then
# consider using age/bl?
# consider using monophyletic groups to test for fossil placement?


write(file=outfileName, colnames, sep=",", append=FALSE)


write(file=outfileName, "\n", append=TRUE)
print("written colnames")

################### calculate the pps stats here #########################


## Iterate through all of the posterior tree files from the simulation analyses
  outline1 = v("Emp")
  # write(file=outfileName, append=TRUE, sep=",", i)

  print("############################")
  print("Start summarising Emp ")
  print("############################")

  if (emp_subset == TRUE) {
    taxa <- readTaxonData(input_dir_emp + "taxa.tsv")
    for (tax in 1:taxa.size()) {
      taxnames[tax] = taxa[tax].getSpeciesName()
    }
  }

  for (j in 1:num_markers) {


  #    inFileName = "output_" + model_name + "/posterior_predictive_sim_" + i + "/" + analysis_name + "_posterior.trees"
  data <- readDiscreteCharacterData(input_dir_emp + markers[j] + ".nex" )

  if (emp_subset == TRUE) {
    data.addMissingTaxa(taxa)
    data2 = data
    data2.removeTaxa(taxnames)
    outtaxa <- data2.taxa()
    for (tax in 1:outtaxa.size()) {
      outnames[tax] = outtaxa[tax].getSpeciesName()
    }
    data.removeTaxa(outnames)
  }

  num_inv         = data.getNumInvariantSites( excludeAmbiguous=FALSE )
  num_inv_amb     = data.getNumInvariantSites( excludeAmbiguous=TRUE )
  print("num_inv done")
  max_gc          = data.maxGcContent( excludeAmbiguous=FALSE )
  max_gc_amb      = data.maxGcContent( excludeAmbiguous=TRUE )
  print("max_gc done")
  min_inv_bl      = data.maxInvariableBlockLength( excludeAmbiguous=FALSE )
  min_inv_bl_amb  = data.maxInvariableBlockLength( excludeAmbiguous=TRUE )
  print("min_gc done")
  max_pd          = data.maxPairwiseDifference( excludeAmbiguous=FALSE )
  max_pd_amb      = data.maxPairwiseDifference( excludeAmbiguous=TRUE )
  print("max_pd done")
  max_var_bl      = data.maxVariableBlockLength( excludeAmbiguous=FALSE )
  max_var_bl_amb  = data.maxVariableBlockLength( excludeAmbiguous=TRUE )
  print("max_var_bl done")
  min_gc          = data.minGcContent( excludeAmbiguous=FALSE )
  min_gc_amb      = data.minGcContent( excludeAmbiguous=TRUE )
  print("min_gc done")
  min_pd          = data.minPairwiseDifference( excludeAmbiguous=FALSE )
  min_pd_amb      = data.minPairwiseDifference( excludeAmbiguous=TRUE )
  print("min_pd done")
  n_char          = data.nchar()
  n_taxa          = data.ntaxa()
  print("n char tax done")
  n_inv_b         = data.numInvariableBlocks( excludeAmbiguous=FALSE )
  n_inv_b_amb     = data.numInvariableBlocks( excludeAmbiguous=TRUE )
  print("n_inv_b done")
  mean_gc         = data.meanGcContent( excludeAmbiguous=FALSE )
  mean_gc_amb     = data.meanGcContent( excludeAmbiguous=TRUE )
  print("mean_gc done")
  mean_gc_1       = data.meanGcContentByCodonPosition(1, excludeAmbiguous=FALSE )
  mean_gc_1_amb   = data.meanGcContentByCodonPosition(1, excludeAmbiguous=TRUE )
  print("mean_gc_1 done")
  mean_gc_2       = data.meanGcContentByCodonPosition(2, excludeAmbiguous=FALSE )
  mean_gc_2_amb   = data.meanGcContentByCodonPosition(2, excludeAmbiguous=TRUE )
  print("mean_gc_2 done")
  mean_gc_3       = data.meanGcContentByCodonPosition(3, excludeAmbiguous=FALSE )
  mean_gc_3_amb   = data.meanGcContentByCodonPosition(3, excludeAmbiguous=TRUE )
  print("mean_gc_3 done")
  var_gc          = data.varGcContent( excludeAmbiguous=FALSE )
  var_gc_amb      = data.varGcContent( excludeAmbiguous=TRUE )
  print("var_gc done")
  var_gc_1        = data.varGcContentByCodonPosition(1, excludeAmbiguous=FALSE )
  var_gc_1_amb    = data.varGcContentByCodonPosition(1, excludeAmbiguous=TRUE )
  print("var_gc_1 done")
  var_gc_2        = data.varGcContentByCodonPosition(2, excludeAmbiguous=FALSE )
  var_gc_2_amb    = data.varGcContentByCodonPosition(2, excludeAmbiguous=TRUE )
  print("var_gc_2 done")
  var_gc_3        = data.varGcContentByCodonPosition(3, excludeAmbiguous=FALSE )
  var_gc_3_amb    = data.varGcContentByCodonPosition(3, excludeAmbiguous=TRUE )
  print("var_gc_3 done")
#  n_taxa_50       = data.numTaxaMissingSequence( 0.5 )
#  n_taxa_30       = data.numTaxaMissingSequence( 0.3 )
#  n_taxa_10       = data.numTaxaMissingSequence( 0.1 )
#  print("n_taxa done")
  theta           = fnWattersonsTheta( data )
  seg_sites       = fnSegregatingSites( data )
  tajima_d        = fnTajimasD( data )
  tajima_pi       = fnTajimasPi( data )
  print("stats done")
  mult_lnl        = data.computeMultinomialProfileLikelihood()
  print("all calcs done")



  #write(file=outfileName, append=TRUE, sep=",",
  outline0 = v(
  num_inv,
  num_inv_amb,
  seg_sites,
  max_gc,
  max_gc_amb,
  min_inv_bl,
  min_inv_bl_amb,
  max_pd,
  max_pd_amb,
  max_var_bl,
  max_var_bl_amb,
  min_gc,
  min_gc_amb,
  min_pd,
  min_pd_amb,
  n_inv_b,
  n_inv_b_amb,
  mean_gc,
  mean_gc_amb,
  mean_gc_1,
  mean_gc_1_amb,
  mean_gc_2,
  mean_gc_2_amb,
  mean_gc_3,
  mean_gc_3_amb,
  var_gc,
  var_gc_amb,
  var_gc_1,
  var_gc_1_amb,
  var_gc_2,
  var_gc_2_amb,
  var_gc_3,
  var_gc_3_amb,
  theta,
  tajima_d,
  tajima_pi,
  mult_lnl)
  if (j > 1) {
    outline2.append(outline0)
  } else if (j == 1) {
    outline2 = outline0
  }
  print("molek calcs saved")
}

emp_data_morph <- readDiscreteCharacterData(input_dir_emp + "AntMegaMatrixMinusAmbig.nex")

print("emp morpho loaded")



if (emp_subset == TRUE) {
  emp_data_morph.addMissingTaxa(taxa)
  emp_data_morph2 = emp_data_morph
  emp_data_morph2.removeTaxa(taxnames)
  outtaxa_morph <- emp_data_morph2.taxa()
  for (tax in 1:outtaxa_morph.size()) {
    outnames_morph[tax] = outtaxa_morph[tax].getSpeciesName()
  }
  emp_data_morph.removeTaxa(outnames_morph)
}

tipfreqs = emp_data_morph.getEmpiricalBaseFrequencies()
tipfreq_0 = tipfreqs[1]
tipfreq_1 = tipfreqs[2]
tipfreq_2 = tipfreqs[3]
tipfreq_3 = tipfreqs[4]
tipfreq_4 = tipfreqs[5]
tipfreq_5 = tipfreqs[6]
tipfreq_6 = tipfreqs[7]
print("tipfreqs done")
n_inv_morpho = emp_data_morph.getNumInvariantSites( excludeAmbiguous=FALSE )
n_inv_morpho_amb = emp_data_morph.getNumInvariantSites( excludeAmbiguous=TRUE )
print("n_inv_morpho done")
max_pd_morpho = emp_data_morph.maxPairwiseDifference( excludeAmbiguous=FALSE )
max_pd_morpho_amb = emp_data_morph.maxPairwiseDifference( excludeAmbiguous=TRUE )
print("max_pd_morpho done")
min_pd_morpho = emp_data_morph.minPairwiseDifference( excludeAmbiguous=FALSE )
min_pd_morpho_amb = emp_data_morph.minPairwiseDifference( excludeAmbiguous=TRUE )
print("min_pd_morpho done")
#write(file=outfileName, append=TRUE, sep=",",
outline3 = v(
  tipfreq_0,
  tipfreq_1,
  tipfreq_2,
  tipfreq_3,
  tipfreq_4,
  tipfreq_5,
  tipfreq_6,
  n_inv_morpho,
  n_inv_morpho_amb,
  max_pd_morpho,
  max_pd_morpho_amb,
  min_pd_morpho,
  min_pd_morpho_amb
)
outline2.append(outline3)
print("morpho calcs saved")
outline = append(outline1, outline2)
write(file=outfileName, append=TRUE, sep=",", outline)
write(file=outfileName, "\n", append=TRUE)

print("Empirical summary done")



###################################
# Summarize posterior simulations #
###################################
colnames <- v("SimID")
outfileName = output_dir + "/simulated_data_" + file_stem + ".csv"

# Molecular Data
for (j in 1:num_markers) {
  # initiate outfile and populate with column names

  colnames2 <- v(
  "Number Invariant Sites" + " " + markers[j],
  "Number Invariant Sites Excluding Ambiguous" + " " + markers[j],
  "Segregating-Sites" + " " + markers[j],
  "Max GC" + " " + markers[j],
  "Max GC Excluding Ambiguous" + " " + markers[j],
  "Max Invariant Block Length" + " " + markers[j],
  "Max Invariant Block Length Excluding Ambiguous" + " " + markers[j],
  "Max Pairwise Difference" + " " + markers[j],
  "Max Pairwise Difference Excluding Ambiguous" + " " + markers[j],
  "Max Variable Block Length" + " " + markers[j],
  "Max Variable Block Length Excluding Ambiguous" + " " + markers[j],
  "Min GC" + " " + markers[j],
  "Min GC Excluding Ambiguous" + " " + markers[j],
  "Min Pairwise Difference" + " " + markers[j],
  "Min Pairwise Difference Excluding Ambiguous" + " " + markers[j],
  "Number Invariable Block" + " " + markers[j],
  "Number Invariable Block Excluding Ambiguous" + " " + markers[j],
  "Mean GC" + " " + markers[j],
  "Mean GC Excluding Ambiguous" + " " + markers[j],
  "Mean GC 1" + " " + markers[j],
  "Mean GC 1 Excluding Ambiguous" + " " + markers[j],
  "Mean GC 2" + " " + markers[j],
  "Mean GC 2 Excluding Ambiguous" + " " + markers[j],
  "Mean GC 3" + " " + markers[j],
  "Mean GC 3 Excluding Ambiguous" + " " + markers[j],
  "Var GC" + " " + markers[j],
  "Var GC Excluding Ambiguous" + " " + markers[j],
  "Var GC 1" + " " + markers[j],
  "Var GC 1 Excluding Ambiguous" + " " + markers[j],
  "Var GC 2" + " " + markers[j],
  "Var GC 2 Excluding Ambiguous" + " " + markers[j],
  "Var GC 3" + " " + markers[j],
  "Var GC 3 Excluding Ambiguous" + " " + markers[j],
  "Theta" + " " + markers[j],
  "Tajima-D" + " " + markers[j],
  "Tajima-Pi" + " " + markers[j],
  "Multinomial-Likelihood" + " " + markers[j]
  )
  colnames2.size()
  colnames.append(colnames2)
  colnames.size()
}

# Morpho Data
# for (k in 1:(n_morpho_states-1)) {  #just pool them all for now, though this may eventually not be reasonable
    colnames3 <- v(
    "Tip State Frequency 0",
    "Tip State Frequency 1",
    "Tip State Frequency 2",
    "Tip State Frequency 3",
    "Tip State Frequency 4",
    "Tip State Frequency 5",
    "Tip State Frequency 6",
    "Number Invariant Sites Morpho",
    "Number Invariant Sites Morpho Excluding Ambiguous",
    "Max Pairwise Difference Morpho",
    "Max Pairwise Difference Morpho Excluding Ambiguous",
    "Min Pairwise Difference Morpho",
    "Min Pairwise Difference Morpho Excluding Ambiguous"
    )
    colnames3.size()
    colnames.append(colnames3)
    colnames.size()
    # later add distinction of using fossil vs extant only, as well as delta of fossil and extant
    # also add state relative time once tracked during inference?
#}


# Fossil ages
# can't do that just yet?
# load and subset trace, within which we got t[i], fossil_normalized[i], and fossil[i]
# compare to fossil min and max then
# consider using age/bl?
# consider using monophyletic groups to test for fossil placement?


write(file=outfileName, colnames, sep=",", append=FALSE)


write(file=outfileName, "\n", append=TRUE)
print("written colnames")

  ################### calculate the pps stats here #########################


  ## Iterate through all of the posterior tree files from the simulation analyses
  for ( i in 1:num_post_sims) {
    outline1 = v(i)
    # write(file=outfileName, append=TRUE, sep=",", i)

    print("############################")
    print("Start summarising Sim " + i)
    print("############################")

    for (j in 1:num_markers) {


    #    inFileName = "output_" + model_name + "/posterior_predictive_sim_" + i + "/" + analysis_name + "_posterior.trees"

    sim_data <- readDiscreteCharacterData(input_dir_sim + "/posterior_predictive_sim_" + i + "/phySeq[" + j + "].nex" )

    num_inv         = sim_data.getNumInvariantSites( excludeAmbiguous=FALSE )
    num_inv_amb     = sim_data.getNumInvariantSites( excludeAmbiguous=TRUE )
    print("num_inv done")
    max_gc          = sim_data.maxGcContent( excludeAmbiguous=FALSE )
    max_gc_amb      = sim_data.maxGcContent( excludeAmbiguous=TRUE )
    print("max_gc done")
    min_inv_bl      = sim_data.maxInvariableBlockLength( excludeAmbiguous=FALSE )
    min_inv_bl_amb  = sim_data.maxInvariableBlockLength( excludeAmbiguous=TRUE )
    print("min_gc done")
    max_pd          = sim_data.maxPairwiseDifference( excludeAmbiguous=FALSE )
    max_pd_amb      = sim_data.maxPairwiseDifference( excludeAmbiguous=TRUE )
    print("max_pd done")
    max_var_bl      = sim_data.maxVariableBlockLength( excludeAmbiguous=FALSE )
    max_var_bl_amb  = sim_data.maxVariableBlockLength( excludeAmbiguous=TRUE )
    print("max_var_bl done")
    min_gc          = sim_data.minGcContent( excludeAmbiguous=FALSE )
    min_gc_amb      = sim_data.minGcContent( excludeAmbiguous=TRUE )
    print("min_gc done")
    min_pd          = sim_data.minPairwiseDifference( excludeAmbiguous=FALSE )
    min_pd_amb      = sim_data.minPairwiseDifference( excludeAmbiguous=TRUE )
    print("min_pd done")
    n_char          = sim_data.nchar()
    n_taxa          = sim_data.ntaxa()
    print("n char tax done")
    n_inv_b         = sim_data.numInvariableBlocks( excludeAmbiguous=FALSE )
    n_inv_b_amb     = sim_data.numInvariableBlocks( excludeAmbiguous=TRUE )
    print("n_inv_b done")
    mean_gc         = sim_data.meanGcContent( excludeAmbiguous=FALSE )
    mean_gc_amb     = sim_data.meanGcContent( excludeAmbiguous=TRUE )
    print("mean_gc done")
    mean_gc_1       = sim_data.meanGcContentByCodonPosition(1, excludeAmbiguous=FALSE )
    mean_gc_1_amb   = sim_data.meanGcContentByCodonPosition(1, excludeAmbiguous=TRUE )
    print("mean_gc_1 done")
    mean_gc_2       = sim_data.meanGcContentByCodonPosition(2, excludeAmbiguous=FALSE )
    mean_gc_2_amb   = sim_data.meanGcContentByCodonPosition(2, excludeAmbiguous=TRUE )
    print("mean_gc_2 done")
    mean_gc_3       = sim_data.meanGcContentByCodonPosition(3, excludeAmbiguous=FALSE )
    mean_gc_3_amb   = sim_data.meanGcContentByCodonPosition(3, excludeAmbiguous=TRUE )
    print("mean_gc_3 done")
    var_gc          = sim_data.varGcContent( excludeAmbiguous=FALSE )
    var_gc_amb      = sim_data.varGcContent( excludeAmbiguous=TRUE )
    print("var_gc done")
    var_gc_1        = sim_data.varGcContentByCodonPosition(1, excludeAmbiguous=FALSE )
    var_gc_1_amb    = sim_data.varGcContentByCodonPosition(1, excludeAmbiguous=TRUE )
    print("var_gc_1 done")
    var_gc_2        = sim_data.varGcContentByCodonPosition(2, excludeAmbiguous=FALSE )
    var_gc_2_amb    = sim_data.varGcContentByCodonPosition(2, excludeAmbiguous=TRUE )
    print("var_gc_2 done")
    var_gc_3        = sim_data.varGcContentByCodonPosition(3, excludeAmbiguous=FALSE )
    var_gc_3_amb    = sim_data.varGcContentByCodonPosition(3, excludeAmbiguous=TRUE )
    print("var_gc_3 done")
#    n_taxa_50       = sim_data.numTaxaMissingSequence( 0.5 )
#    n_taxa_30       = sim_data.numTaxaMissingSequence( 0.3 )
#    n_taxa_10       = sim_data.numTaxaMissingSequence( 0.1 )
#    print("n_taxa done")
    theta           = fnWattersonsTheta( sim_data )
    seg_sites       = fnSegregatingSites( sim_data )
    tajima_d        = fnTajimasD( sim_data )
    tajima_pi       = fnTajimasPi( sim_data )
    print("stats done")
    mult_lnl        = sim_data.computeMultinomialProfileLikelihood()
    print("all calcs done")



    #write(file=outfileName, append=TRUE, sep=",",
    outline0 = v(
    num_inv,
    num_inv_amb,
    seg_sites,
    max_gc,
    max_gc_amb,
    min_inv_bl,
    min_inv_bl_amb,
    max_pd,
    max_pd_amb,
    max_var_bl,
    max_var_bl_amb,
    min_gc,
    min_gc_amb,
    min_pd,
    min_pd_amb,
    n_inv_b,
    n_inv_b_amb,
    mean_gc,
    mean_gc_amb,
    mean_gc_1,
    mean_gc_1_amb,
    mean_gc_2,
    mean_gc_2_amb,
    mean_gc_3,
    mean_gc_3_amb,
    var_gc,
    var_gc_amb,
    var_gc_1,
    var_gc_1_amb,
    var_gc_2,
    var_gc_2_amb,
    var_gc_3,
    var_gc_3_amb,
    theta,
    tajima_d,
    tajima_pi,
    mult_lnl)
    if (j > 1) {
      outline2.append(outline0)
    } else if (j == 1) {
      outline2 = outline0
    }
    print("molek calcs saved")
  }

  if (morpho_model == "Mk") {
    for (k in 1:(n_morpho_states-1)) {  #just pool them all for now, though this may eventually not be reasonable
      sim_data_morph[k] <- readDiscreteCharacterData(input_dir_sim + "posterior_predictive_sim_" + i + "/m_morph[" + k + "].nex" )
    }
    # when concatenating matrices, matrix with the highest
    sim_data_morph_combo = concatenate( sim_data_morph[6], sim_data_morph[1],  sim_data_morph[2],  sim_data_morph[3],  sim_data_morph[4],  sim_data_morph[5])
    print("morpho concatenated")
  } else if (morpho_model == "SHDM") {
    sim_data_morph_combo <- readDiscreteCharacterData(input_dir_sim + "posterior_predictive_sim_" + i + "/phyMorpho.nex" )
  }

  tipfreqs = sim_data_morph_combo.getEmpiricalBaseFrequencies()
  tipfreq_0 = tipfreqs[1]
  tipfreq_1 = tipfreqs[2]
  tipfreq_2 = tipfreqs[3]
  tipfreq_3 = tipfreqs[4]
  tipfreq_4 = tipfreqs[5]
  tipfreq_5 = tipfreqs[6]
  tipfreq_6 = tipfreqs[7]
  print("tipfreqs done")
  n_inv_morpho = sim_data_morph_combo.getNumInvariantSites( excludeAmbiguous=FALSE )
  n_inv_morpho_amb = sim_data_morph_combo.getNumInvariantSites( excludeAmbiguous=TRUE )
  print("n_inv_morpho done")
  max_pd_morpho = sim_data_morph_combo.maxPairwiseDifference( excludeAmbiguous=FALSE )
  max_pd_morpho_amb = sim_data_morph_combo.maxPairwiseDifference( excludeAmbiguous=TRUE )
  print("max_pd_morpho done")
  min_pd_morpho = sim_data_morph_combo.minPairwiseDifference( excludeAmbiguous=FALSE )
  min_pd_morpho_amb = sim_data_morph_combo.minPairwiseDifference( excludeAmbiguous=TRUE )
  print("min_pd_morpho done")
  #write(file=outfileName, append=TRUE, sep=",",
  outline3 = v(
    tipfreq_0,
    tipfreq_1,
    tipfreq_2,
    tipfreq_3,
    tipfreq_4,
    tipfreq_5,
    tipfreq_6,
    n_inv_morpho,
    n_inv_morpho_amb,
    max_pd_morpho,
    max_pd_morpho_amb,
    min_pd_morpho,
    min_pd_morpho_amb
  )
  outline2.append(outline3)
  print("morpho calcs saved")
  outline = append(outline1, outline2)
  write(file=outfileName, append=TRUE, sep=",", outline)
  write(file=outfileName, "\n", append=TRUE)
}


print("Done summarising statistics.")
